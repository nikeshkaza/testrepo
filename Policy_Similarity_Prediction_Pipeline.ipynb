{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Similarity Engine - Prediction Pipeline",
    "",
    "## \ud83d\ude80 Inference on New Business Policies",
    "",
    "This notebook loads trained models and performs similarity retrieval for new policies.",
    "",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup",
    "import numpy as np",
    "import pandas as pd",
    "import joblib",
    "import json",
    "from datetime import datetime",
    "",
    "print(\"\u2713 Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all artifacts",
    "hybrid_engine = joblib.load('/home/claude/models/hybrid_engine.pkl')",
    "scaler = joblib.load('/home/claude/models/scaler.pkl')",
    "frequency_encodings = joblib.load('/home/claude/models/frequency_encodings.pkl')",
    "metadata = joblib.load('/home/claude/models/metadata.pkl')",
    "identifiers = pd.read_csv('/home/claude/models/policy_identifiers.csv')",
    "",
    "# Load configuration",
    "with open('/home/claude/models/config.json', 'r') as f:",
    "    config = json.load(f)",
    "",
    "print(\"=\"*80)",
    "print(\"\u2713 MODELS LOADED\")",
    "print(\"=\"*80)",
    "print(f\"Model Type: {config['model_type']}\")",
    "print(f\"Model Version: {metadata['model_version']}\")",
    "print(f\"Training Date: {metadata['training_date']}\")",
    "print(f\"Total Features: {config['n_features']}\")",
    "print(f\"Training Policies: {config['n_policies']:,}\")",
    "",
    "# Load text model if needed",
    "try:",
    "    from sentence_transformers import SentenceTransformer",
    "    text_model = SentenceTransformer('all-MiniLM-L6-v2')",
    "    print(\"\u2713 Text embedding model loaded\")",
    "except:",
    "    text_model = None",
    "    print(\"\u26a0\ufe0f Text model not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new_policy(policy_dict):",
    "    '''Apply same preprocessing as training'''",
    "    df = pd.DataFrame([policy_dict])",
    "    ",
    "    # Date features",
    "    if 'Effective Date' in df.columns:",
    "        df['Effective Date'] = pd.to_datetime(df['Effective Date'])",
    "        df['Expiration Date'] = pd.to_datetime(df['Expiration Date'])",
    "        df['policy_tenure_days'] = (df['Expiration Date'] - df['Effective Date']).dt.days",
    "        df['effective_month'] = df['Effective Date'].dt.month",
    "        df['month_sin'] = np.sin(2 * np.pi * df['effective_month'] / 12)",
    "        df['month_cos'] = np.cos(2 * np.pi * df['effective_month'] / 12)",
    "        df = df.drop(columns=['Effective Date', 'Expiration Date'])",
    "    ",
    "    # Geospatial",
    "    if 'LAT_NEW' in df.columns and 'LATIT' in df.columns:",
    "        df['latitude'] = df[['LAT_NEW', 'LATIT']].mean(axis=1)",
    "        df['longitude'] = df[['LONG_NEW', 'LONGIT']].mean(axis=1)",
    "        df = df.drop(columns=['LAT_NEW', 'LATIT', 'LONG_NEW', 'LONGIT'], errors='ignore')",
    "    ",
    "    if 'latitude' in df.columns:",
    "        NYC_LAT, NYC_LON = 40.7128, -74.0060",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [df['latitude'].iloc[0], df['longitude'].iloc[0], NYC_LAT, NYC_LON])",
    "        dlat, dlon = lat2 - lat1, lon2 - lon1",
    "        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2",
    "        df['dist_from_nyc_km'] = 2 * 6371 * np.arcsin(np.sqrt(a))",
    "    ",
    "    return df",
    "",
    "print(\"\u2713 Preprocessing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_new_policy(df):",
    "    '''Encode features matching training'''",
    "    df_enc = df.copy()",
    "    ",
    "    # One-hot encoding (match training columns)",
    "    df_enc = pd.get_dummies(df_enc, drop_first=True)",
    "    ",
    "    # Frequency encoding",
    "    for col, freq_map in frequency_encodings.items():",
    "        if col in df.columns:",
    "            df_enc[f'{col}_freq'] = df[col].map(freq_map).fillna(0)",
    "    ",
    "    # Text embeddings",
    "    if text_model and metadata['text_fields']:",
    "        for col in metadata['text_fields']:",
    "            if col in df.columns:",
    "                text = df[col].fillna('').astype(str).tolist()",
    "                embeddings = text_model.encode(text)",
    "                for i, val in enumerate(embeddings[0]):",
    "                    df_enc[f'{col}_emb_{i}'] = val",
    "    ",
    "    # Align with training features",
    "    for col in metadata['feature_names']:",
    "        if col not in df_enc.columns:",
    "            df_enc[col] = 0",
    "    ",
    "    df_enc = df_enc[metadata['feature_names']]",
    "    ",
    "    return df_enc",
    "",
    "print(\"\u2713 Encoding function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Main Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_policies(new_policy_dict):",
    "    '''",
    "    Main inference function",
    "    ",
    "    Args:",
    "        new_policy_dict: Raw policy attributes as dictionary",
    "    ",
    "    Returns:",
    "        results_df: DataFrame with similar policies",
    "        explanation: Dictionary with explanations",
    "    '''",
    "    # 1. Preprocess",
    "    df_preprocessed = preprocess_new_policy(new_policy_dict)",
    "    ",
    "    # 2. Encode",
    "    df_encoded = encode_new_policy(df_preprocessed)",
    "    ",
    "    # 3. Scale",
    "    X_scaled = scaler.transform(df_encoded)",
    "    ",
    "    # 4. Search",
    "    if hybrid_engine.n_text_features > 0:",
    "        X_struct = X_scaled[0, :hybrid_engine.n_struct_features]",
    "        X_text = X_scaled[0, hybrid_engine.n_struct_features:]",
    "        sim_indices, distances = hybrid_engine.find_similar(X_struct, X_text)",
    "    else:",
    "        sim_indices, distances = hybrid_engine.find_similar(X_scaled[0], None)",
    "    ",
    "    # 5. Retrieve records",
    "    results = identifiers.iloc[sim_indices].copy()",
    "    results['distance'] = distances",
    "    results['similarity_score'] = 1 / (1 + distances)",
    "    results['rank'] = range(1, len(sim_indices) + 1)",
    "    ",
    "    # 6. Generate explanation",
    "    explanation = {",
    "        'query_summary': {",
    "            'features_used': len(metadata['feature_names']),",
    "            'model_version': metadata['model_version']",
    "        },",
    "        'similar_policies': [",
    "            {",
    "                'rank': i+1,",
    "                'policy_id': results.iloc[i]['System Reference Number'],",
    "                'distance': distances[i],",
    "                'similarity_score': 1 / (1 + distances[i])",
    "            }",
    "            for i in range(len(sim_indices))",
    "        ]",
    "    }",
    "    ",
    "    return results, explanation",
    "",
    "print(\"\u2713 Inference pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new policy",
    "new_policy = {",
    "    'Effective Date': '2024-01-01',",
    "    'Expiration Date': '2025-01-01',",
    "    'policy_tiv': 5000000,",
    "    'Revenue': 10000000,",
    "    'highest_location_tiv': 2000000,",
    "    'POSTAL_CD': 10001,",
    "    'LAT_NEW': 40.7128,",
    "    'LATIT': 40.7128,",
    "    'LONGIT': -74.0060,",
    "    'LONG_NEW': -74.0060,",
    "    'SIC_1': 2345,",
    "    'EMP_TOT': 250,",
    "    'SLES_VOL': 8000000,",
    "    'YR_STRT': 1990,",
    "    'STAT_IND': 1,",
    "    'SUBS_IND': 0,",
    "    'outliers': 0,",
    "    '2012 NAIC Description': 'Property Insurance',",
    "    'Programme Type': 'Corporate',",
    "    'Portfolio Segmentation': 'Manufacturing',",
    "    'Product': 'Property',",
    "    'Sub Product': 'Standard',",
    "    'Policy Industry Description': 'Manufacturing - Chemical',",
    "    'LOCATION': 'NY',",
    "    'Short Tail / Long Tail': 'Short'",
    "}",
    "",
    "print(\"Searching for similar policies...\")",
    "results, explanation = find_similar_policies(new_policy)",
    "",
    "print(\"\\n\" + \"=\"*80)",
    "print(\"SIMILAR POLICIES FOUND\")",
    "print(\"=\"*80)",
    "print(results[['System Reference Number', 'rank', 'similarity_score', 'distance']])",
    "",
    "print(\"\\n\" + \"=\"*80)",
    "print(\"EXPLANATION\")",
    "print(\"=\"*80)",
    "print(json.dumps(explanation, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_find_similar(policies_list):",
    "    '''Process multiple policies at once'''",
    "    results_list = []",
    "    ",
    "    for i, policy in enumerate(policies_list):",
    "        print(f\"Processing policy {i+1}/{len(policies_list)}...\")",
    "        results, _ = find_similar_policies(policy)",
    "        results['query_id'] = i",
    "        results_list.append(results)",
    "    ",
    "    return pd.concat(results_list, ignore_index=True)",
    "",
    "print(\"\u2713 Batch processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results",
    "results.to_csv('/home/claude/similarity_results.csv', index=False)",
    "",
    "# Save explanation",
    "with open('/home/claude/similarity_explanation.json', 'w') as f:",
    "    json.dump(explanation, f, indent=2)",
    "",
    "print(\"=\"*80)",
    "print(\"\u2713 RESULTS SAVED\")",
    "print(\"=\"*80)",
    "print(\"Results CSV: /home/claude/similarity_results.csv\")",
    "print(\"Explanation JSON: /home/claude/similarity_explanation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary",
    "",
    "### Key Capabilities",
    "\u2705 Load trained models  ",
    "\u2705 Preprocess new policies  ",
    "\u2705 Generate similarity scores  ",
    "\u2705 Provide explainability  ",
    "\u2705 Support batch processing  ",
    "",
    "### Next Steps",
    "1. Deploy as API endpoint",
    "2. Integrate with underwriting system",
    "3. Monitor retrieval quality",
    "4. Collect feedback for retraining",
    "",
    "---",
    "",
    "**Status:** \u2705 Ready for Production Use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}